{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30dbd1e4",
   "metadata": {},
   "source": [
    "# Example\n",
    "This examples shows how to build an equivariant neural network using our method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a2cbcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from e3nn.o3 import rand_matrix\n",
    "\n",
    "from tensor_frames.lframes import LFrames\n",
    "from tensor_frames.lframes.learning_lframes import WrappedLearnedLFrames\n",
    "from tensor_frames.nn.embedding.radial import TrivialRadialEmbedding\n",
    "from tensor_frames.nn.gcn_conv import GCNConv\n",
    "from tensor_frames.nn.local_global import FromLocalToGlobalFrame\n",
    "from tensor_frames.reps import TensorReps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2821d1e",
   "metadata": {},
   "source": [
    "First we create a SimpleLoCaConv class, that uses a learned local frames and a GCNConv layer, which uses tensorial messages. The `WrappedLearnedLFrames` module uses a radial embedding to compute scalar features from the positions, which are also used in the calculation of the local frames.\n",
    "\n",
    "The forward pass executes the following steps:\n",
    "1. Compute local features and local frames using the `lframes_module`.\n",
    "2. Apply the GCN convolution in the local frame using tensorial message passing.\n",
    "3. Transform the output features back to the global frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa657c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLoCaConv(torch.nn.Module):\n",
    "    def __init__(self, in_reps, out_reps):\n",
    "        super().__init__()\n",
    "        self.lframes_module = WrappedLearnedLFrames(\n",
    "            in_reps=in_reps, hidden_channels=[128], radial_module=TrivialRadialEmbedding()\n",
    "        )\n",
    "        self.gcn_conv = GCNConv(in_reps, out_reps)\n",
    "        self.from_local_to_global = FromLocalToGlobalFrame(out_reps)\n",
    "\n",
    "    def forward(self, x, pos, batch, edge_index):\n",
    "        x_local, lframes = self.lframes_module(x=x, pos=pos, batch=batch, edge_index=edge_index)\n",
    "        out_local = self.gcn_conv(x=x_local, edge_index=edge_index, lframes=lframes)\n",
    "        out_global = self.from_local_to_global(x=out_local, lframes=lframes)\n",
    "        return out_global"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed5d5e3",
   "metadata": {},
   "source": [
    "Now we generate some random data. We create a graph with 10 nodes, where each node has 5 scalar features and 1 vectorial feature (8 components). The graph is fully connected, meaning every node is connected to every other node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ebe934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy data consisting of 100 nodes in 3D space with 5 scalar features and 1 vectorial feature each\n",
    "pos = torch.randn(10, 3)  # vectorial positions\n",
    "features = torch.randn(10, 5 + 3)  # 5 scalar + 1 vectorial (3) = 8 components\n",
    "edge_index = torch.stack(\n",
    "    torch.meshgrid(torch.arange(10), torch.arange(10), indexing=\"ij\")\n",
    ").reshape(\n",
    "    2, -1\n",
    ")  # fully connected graph\n",
    "batch = torch.zeros(pos.shape[0], dtype=torch.long)  # all nodes belong to the same graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c779fe04",
   "metadata": {},
   "source": [
    "Next we define the transformation behavior of the features through the `TensorReps` class. Here we specify that the input features consist of 5 scalar features and 1 vectorial feature, and the output features should have the same structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ff79898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "in_reps = TensorReps(\"5x0n + 1x1n\")  # 5 scalar features + 1 vectorial feature\n",
    "out_reps = TensorReps(\"5x0n + 1x1n\")  # 5 scalar features + 1 vectorial feature as output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e964d57",
   "metadata": {},
   "source": [
    "Now we can create a model instance and use the random data to perform a forward pass.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b1e64fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 8])\n"
     ]
    }
   ],
   "source": [
    "model = SimpleLoCaConv(in_reps=in_reps, out_reps=out_reps)\n",
    "\n",
    "# forward pass\n",
    "output = model(x=features, pos=pos, edge_index=edge_index, batch=batch)\n",
    "print(output.shape)  # should be [100, 6] -> 5 scalar + 1 vectorial (3) = 6 features per node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a544f930",
   "metadata": {},
   "source": [
    "Next, we can check that the network is indeed equivariant. To do this we generate a random global rotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d93b3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotation:\n",
      " torch.Size([10, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# now check the equivariance of the model\n",
    "global_rot = rand_matrix(1).repeat(100, 1, 1)\n",
    "global_frame = LFrames(rand_matrix().repeat(pos.shape[0], 1, 1))\n",
    "print(\"Rotation:\\n\", global_frame.matrices.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb34a9a",
   "metadata": {},
   "source": [
    "We transform the positions and the node features through the corresponding representation. The `get_transform_class()` function generates a module, which transforms the features respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec70a87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rotate positions\n",
    "rotated_pos = TensorReps(\"1x1n\").get_transform_class().transform_coeffs(pos, global_frame)\n",
    "rotated_features = in_reps.get_transform_class().transform_coeffs(features, global_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e971f95",
   "metadata": {},
   "source": [
    "If we rotate the output features back to the original frame, they should match the output of the unrotated input features. This confirms that our network is equivariant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b8ecfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "rotated_output = model(x=rotated_features, pos=rotated_pos, edge_index=edge_index, batch=batch)\n",
    "unrotated_output = out_reps.get_transform_class().transform_coeffs(\n",
    "    rotated_output, global_frame.inverse_lframes()\n",
    ")\n",
    "\n",
    "print(torch.allclose(output, unrotated_output, atol=1e-4))  # should be True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
